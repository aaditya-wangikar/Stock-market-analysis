{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adbb91b0-7508-4b13-9db1-de4ffb1aa8e3",
   "metadata": {},
   "source": [
    "# Stock market analysis ðŸ“ˆ\n",
    "This project focuses on analyzing stock market data to uncover trends, evaluate performance, and support data-driven investment decisions. The analysis includes importing historical stock prices, cleaning and preparing the data, performing exploratory data analysis (EDA), and visualizing key financial metrics such as price trends, volume movements, and returns.\n",
    "\n",
    "By using Python-based this analysis helps identify:\n",
    "- Stock price patterns over time\n",
    "- Volatility and momentum\n",
    "- Correlations with market indices\n",
    "- Opportunities for long-term or short-term investment\n",
    "- Technical indicators, machine learning models for prediction\n",
    "- Portfolio optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f8635b-c084-414b-a274-7f7da1d7c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from datetime import timedelta\n",
    "from scipy.optimize import minimize\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import pdb\n",
    "import os\n",
    "import warnings\n",
    "import pdb\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import argrelextrema\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "warnings.filterwarnings('ignore')\n",
    "# Define the directory name\n",
    "directory = \"Files\"\n",
    "# Check if it exists\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    print(f\"âœ… Directory '{directory}' created.\")\n",
    "else:\n",
    "    print(f\"ðŸ“‚ Directory '{directory}' already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d8be3b-f91a-4dc1-b319-0d84d9d1d61c",
   "metadata": {},
   "source": [
    "User requirements and trading stratergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0539b570-3da4-4f98-b249-e8e98c83f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_stocks = input(\"\"\"\n",
    "                       Analyze stocks for:\n",
    "                           1. Top performing stocks overall\n",
    "                           2. Top performing stocks particular sector\n",
    "                           3. User specific stocks\n",
    "                       \"\"\")\n",
    "period = input(\"Enter period to analyze all the stocks (e.g., 14d, 1mo, 6mo, 1y): \").strip()\n",
    "\n",
    "trading_stratergy = input(\"\"\"What is your trading stratergy?\n",
    "                          1. Long term\n",
    "                          2. Intraday\n",
    "                          \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b969e581-37c2-4528-9eca-a0b3c2a06f13",
   "metadata": {},
   "source": [
    "## Sector stocks\n",
    "Top performing stocks from various sectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bbf974-98c7-4566-805f-be96c522cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sector_stocks(index, return_all = False):\n",
    "    nifty50_stocks = [\n",
    "        'RELIANCE.NS', 'TCS.NS', 'INFY.NS', 'HDFCBANK.NS', 'ICICIBANK.NS',\n",
    "        'LT.NS', 'SBIN.NS', 'HINDUNILVR.NS', 'KOTAKBANK.NS', 'ITC.NS',\n",
    "        'AXISBANK.NS', 'BAJFINANCE.NS', 'MARUTI.NS', 'ASIANPAINT.NS',\n",
    "        'SUNPHARMA.NS', 'TITAN.NS', 'HCLTECH.NS', 'ULTRACEMCO.NS', 'WIPRO.NS',\n",
    "        'NESTLEIND.NS', 'GRASIM.NS', 'POWERGRID.NS', 'JSWSTEEL.NS', 'TECHM.NS',\n",
    "        'NTPC.NS', 'BAJAJFINSV.NS', 'ADANIENT.NS', 'COALINDIA.NS', 'DRREDDY.NS',\n",
    "        'HEROMOTOCO.NS', 'CIPLA.NS', 'BRITANNIA.NS', 'DIVISLAB.NS', 'TATAMOTORS.NS',\n",
    "        'BPCL.NS', 'EICHERMOT.NS', 'M&M.NS', 'HINDALCO.NS', 'BHARTIARTL.NS',\n",
    "        'TATASTEEL.NS', 'ONGC.NS', 'INDUSINDBK.NS', 'UPL.NS', 'SHREECEM.NS',\n",
    "        'BAJAJ-AUTO.NS', 'SBILIFE.NS', 'APOLLOHOSP.NS', 'HDFCLIFE.NS', 'ICICIPRULI.NS'\n",
    "    ]\n",
    "    \n",
    "    ai_stocks_nse = [\n",
    "        \"TATAELXSI.NS\",      # Tata Elxsi â€“ AI in automotive, healthcare, media\n",
    "        \"LTTS.NS\",           # L&T Technology Services â€“ AI + IoT + embedded\n",
    "        \"PERSISTENT.NS\",     # Persistent Systems â€“ AI/ML in cloud apps\n",
    "        \"TECHM.NS\",          # Tech Mahindra â€“ Gen AI platforms, NLP\n",
    "        \"INFY.NS\",           # Infosys â€“ AI for automation & business analytics\n",
    "        \"TCS.NS\",            # TCS â€“ AI consulting, cloud, and IP platforms\n",
    "        \"HCLTECH.NS\",        # HCLTech â€“ AI in cybersecurity & automation\n",
    "        \"COFORGE.NS\",        # Coforge â€“ AI-driven digital transformation\n",
    "        \"MPHASIS.NS\",        # Mphasis â€“ Applied AI for finance and insurance\n",
    "        \"WIPRO.NS\"           # Wipro â€“ Generative AI, ML platforms\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    defence_stocks = [\n",
    "    \"HAL.NS\",         # Hindustan Aeronautics Ltd â€“ Fighter jets, helicopters\n",
    "    \"BEL.NS\",         # Bharat Electronics Ltd â€“ Radars, avionics, electronics\n",
    "    \"BDL.NS\",         # Manufacturer of missiles: Akash, Astra, Milan, and torpedoes\n",
    "    \"BEML.NS\",        # BEML Ltd â€“ Military trucks, earthmovers\n",
    "    \"MAZDOCK.NS\",     # Mazagon Dock â€“ Warship & submarine builder\n",
    "    \"COCHINSHIP.NS\",  # Cochin Shipyard â€“ Naval ships, aircraft carriers\n",
    "    \"MTARTECH.NS\",    # MTAR Technologies â€“ Precision components for DRDO/ISRO\n",
    "    \"DATA PATTERNS.NS\",# Data Patterns â€“ Defense electronics and systems\n",
    "    # \"TANEJAERO.NS\",   # Taneja Aerospace â€“ Aircraft parts, airfield infrastructure\n",
    "    \"SOLARA.NS\",      # Solara Active Pharma (indirectly contributes to defense health)\n",
    "    \"SOLARINDS.NS\",   # Solar industries\n",
    "    \"PARAS.NS\",       # Paras Defence â€“ Space, optics, electronics\n",
    "    \"TITAGARH.NS\",     # Titagarh Rail Systems â€“ Defense wagons, naval components\n",
    "    \"DYNAMATECH.NS\",  # Dynamatic Technologies â€“ Aerospace & defense systems\n",
    "    \"IDEAFORGE.NS\",   # ideaForge Technology â€“ Military-grade drones\n",
    "    \"ASTRA.MICRO.NS\", # Astra Microwave â€“ Defense radars and RF systems\n",
    "    \"MIRZAINT.NS\"     # Mirza International â€“ Military boots, apparel (indirect)\n",
    "    \"DCXINDIA.NS\"     # DCX Systems operates in system integration, cable & wire harness fabrication, and electronics for defense and aerospace sectors\n",
    "    \n",
    "]\n",
    "    \n",
    "    pharma_stocks_nse = [\n",
    "        \"SUNPHARMA.NS\",       # Sun Pharmaceutical Industries\n",
    "        \"DIVISLAB.NS\",        # Divi's Laboratories\n",
    "        \"DRREDDY.NS\",         # Dr. Reddy's Laboratories\n",
    "        \"CIPLA.NS\",           # Cipla Ltd\n",
    "        \"AUROPHARMA.NS\",      # Aurobindo Pharma\n",
    "        \"LUPIN.NS\",           # Lupin Ltd\n",
    "        \"ALKEM.NS\",           # Alkem Laboratories\n",
    "        \"ZYDUSLIFE.NS\",       # Zydus Lifesciences (formerly Cadila)\n",
    "        \"GLENMARK.NS\",        # Glenmark Pharmaceuticals\n",
    "        \"BIOCON.NS\",          # Biocon Ltd\n",
    "        \"IPCALAB.NS\",         # Ipca Laboratories\n",
    "        \"TORNTPHARM.NS\",      # Torrent Pharmaceuticals\n",
    "        \"ABBOTINDIA.NS\",      # Abbott India\n",
    "        \"PFIZER.NS\",          # Pfizer India\n",
    "        \"SANOFI.NS\",          # Sanofi India\n",
    "        \"NATCOPHARM.NS\",      # Natco Pharma\n",
    "        \"ERIS.NS\",            # Eris Lifesciences\n",
    "        \"AJANTPHARM.NS\",      # Ajanta Pharma\n",
    "        \"GLAND.NS\",           # Gland Pharma\n",
    "        \"JUBLINGREA.NS\"       # Jubilant Ingrevia (pharma + chemicals)\n",
    "    ]\n",
    "    \n",
    "    energy_stocks_nse = [\n",
    "        \"RELIANCE.NS\",     # Reliance Industries - Oil, gas, green energy\n",
    "        \"ONGC.NS\",         # Oil & Natural Gas Corporation - Exploration\n",
    "        \"IOC.NS\",          # Indian Oil Corporation - Refining & retail\n",
    "        \"BPCL.NS\",         # Bharat Petroleum - Oil marketing\n",
    "        \"HPCL.NS\",         # Hindustan Petroleum - Oil marketing\n",
    "        \"GAIL.NS\",         # Gas Authority of India - Gas distribution\n",
    "        \"NTPC.NS\",         # National Thermal Power Corp - Power generation\n",
    "        \"POWERGRID.NS\",    # Power Grid Corp - Transmission\n",
    "        \"TATAPOWER.NS\",    # Tata Power - Conventional + solar\n",
    "        \"ADANIGREEN.NS\",   # Adani Green Energy - Renewable energy\n",
    "        \"ADANITRANS.NS\",   # Adani Transmission\n",
    "        \"ADANIPOWER.NS\",   # Adani Power - Thermal\n",
    "        \"NHPC.NS\",         # National Hydro Power Corp - Hydro\n",
    "        \"SJVN.NS\",         # Satluj Jal Vidyut Nigam - Hydro + solar\n",
    "        \"COALINDIA.NS\",    # Coal India - Coal mining\n",
    "        \"JSWENERGY.NS\",    # JSW Energy - Thermal + renewables\n",
    "        \"TORNTPOWER.NS\",   # Torrent Power - Generation + distribution\n",
    "        \"KPIGREEN.NS\",     # K.P.I. Green Energy - Solar developer\n",
    "        \"INOXWIND.NS\",     # Inox Wind - Wind turbine manufacturer\n",
    "        \"IGL.NS\",          # Indraprastha Gas Ltd - Gas distribution\n",
    "        \"MGL.NS\"           # Mahanagar Gas Ltd - City gas distribution\n",
    "    ]\n",
    "    \n",
    "    fmcg_stocks_nse = [\n",
    "        \"HINDUNILVR.NS\",   # Hindustan Unilever â€“ Market leader in personal/home care\n",
    "        \"ITC.NS\",          # ITC â€“ Cigarettes, foods, personal care\n",
    "        \"NESTLEIND.NS\",    # Nestle India â€“ Packaged foods, beverages\n",
    "        \"BRITANNIA.NS\",    # Britannia Industries â€“ Biscuits, dairy, bakery\n",
    "        \"DABUR.NS\",        # Dabur India â€“ Ayurvedic and healthcare products\n",
    "        \"MARICO.NS\",       # Marico â€“ Hair oil, edible oil (Parachute, Saffola)\n",
    "        \"COLPAL.NS\",       # Colgate-Palmolive â€“ Oral care\n",
    "        \"EMAMILTD.NS\",     # Emami â€“ Personal care & healthcare\n",
    "        \"GODREJCP.NS\",     # Godrej Consumer â€“ Household & personal care\n",
    "        \"BAJAJCON.NS\",     # Bajaj Consumer â€“ Hair oil\n",
    "        \"HATSUN.NS\",       # Hatsun Agro â€“ Dairy products\n",
    "        \"AVANTIFEED.NS\",   # Avanti Feeds â€“ Aqua feed (semi-FMCG)\n",
    "        \"HERITGFOOD.NS\",   # Heritage Foods â€“ Dairy\n",
    "        \"VSTIND.NS\",       # VST Industries â€“ Tobacco (smaller than ITC)\n",
    "        \"ZYDUSWELL.NS\",    # Zydus Wellness â€“ Nutraceuticals, wellness\n",
    "        \"PATANJALI.NS\",    # Patanjali Foods â€“ Edible oil, FMCG (Ruchi Soya rebranded)\n",
    "        \"VARUNBEVER.NS\",   # Varun Beverages â€“ PepsiCo bottling partner\n",
    "        \"RADICO.NS\",       # Radico Khaitan â€“ Liquor (FMCG-beverage)\n",
    "        \"MANPASAND.NS\",    # Manpasand Beverages (low volume/illiquid)\n",
    "        \"TASTYBITE.NS\"     # Tasty Bite â€“ Ready-to-eat food (small-cap)\n",
    "    ]\n",
    "    \n",
    "    banking_stocks_nse = [\n",
    "        # ðŸ”µ Private Sector Banks\n",
    "        \"HDFCBANK.NS\",       # HDFC Bank\n",
    "        \"ICICIBANK.NS\",      # ICICI Bank\n",
    "        \"AXISBANK.NS\",       # Axis Bank\n",
    "        \"KOTAKBANK.NS\",      # Kotak Mahindra Bank\n",
    "        \"INDUSINDBK.NS\",     # IndusInd Bank\n",
    "        \"IDFCFIRSTB.NS\",     # IDFC First Bank\n",
    "        \"RBLBANK.NS\",        # RBL Bank\n",
    "        \"CSBBANK.NS\",        # CSB Bank\n",
    "        \"DCBBANK.NS\",        # DCB Bank\n",
    "        \"YESBANK.NS\",        # Yes Bank\n",
    "        \"KARURVYSYA.NS\",     # Karur Vysya Bank\n",
    "        \"SOUTHBANK.NS\",      # South Indian Bank\n",
    "        \"CITYUNION.NS\",      # City Union Bank\n",
    "    \n",
    "        # ðŸ”´ Public Sector Banks (PSBs)\n",
    "        \"SBIN.NS\",           # State Bank of India\n",
    "        \"BANKBARODA.NS\",     # Bank of Baroda\n",
    "        \"PNB.NS\",            # Punjab National Bank\n",
    "        \"UNIONBANK.NS\",      # Union Bank of India\n",
    "        \"CANBK.NS\",          # Canara Bank\n",
    "        \"INDIANB.NS\",        # Indian Bank\n",
    "        \"BANKINDIA.NS\",      # Bank of India\n",
    "        \"UCOBANK.NS\",        # UCO Bank\n",
    "        \"IOB.NS\",            # Indian Overseas Bank\n",
    "        \"CENTRALBK.NS\",      # Central Bank of India\n",
    "        \"MAHABANK.NS\"        # Bank of Maharashtra\n",
    "    ]\n",
    "    \n",
    "    infra_stocks_nse = [\n",
    "        # ðŸš§ Core Infra & EPC (Engineering, Procurement, Construction)\n",
    "        \"LT.NS\",             # Larsen & Toubro â€“ Engineering & construction leader\n",
    "        \"NBCC.NS\",           # NBCC (India) â€“ Govt infra developer\n",
    "        \"IRCON.NS\",          # IRCON International â€“ Railways infra\n",
    "        \"RVNL.NS\",           # Rail Vikas Nigam Ltd â€“ Rail infra execution\n",
    "        \"PNCINFRA.NS\",       # PNC Infratech â€“ Roads & highways\n",
    "        \"KNRCON.NS\",         # KNR Constructions â€“ Roads & irrigation\n",
    "        \"HGINFRA.NS\",        # H.G. Infra â€“ Highway contractor\n",
    "        \"NCC.NS\",            # NCC Ltd â€“ Multi-sector infrastructure\n",
    "        \"ASHOKA.NS\",         # Ashoka Buildcon â€“ Roads, bridges, power\n",
    "        \"GPTINFRA.NS\",       # GPT Infraprojects â€“ Civil & rail infrastructure\n",
    "    \n",
    "        # ðŸ›£ï¸ Roads & Highways (HAM/EPC)\n",
    "        \"DILIPBUILCON.NS\",   # Dilip Buildcon â€“ Large road infra player\n",
    "        \"IRB.NS\",            # IRB Infra â€“ Toll operator, highways\n",
    "        \"HGIEL.NS\",          # H.G. Infra Engineering Ltd\n",
    "    \n",
    "        # âš¡ Power & Utility Infra\n",
    "        \"POWERGRID.NS\",      # Power Grid Corp â€“ Power transmission infra\n",
    "        \"NTPC.NS\",           # NTPC â€“ Power generation\n",
    "        \"RECLTD.NS\",         # Rural Electrification Corp â€“ Power finance\n",
    "        \"PFC.NS\",            # Power Finance Corp\n",
    "    \n",
    "        # âš“ Ports & Transport Infra\n",
    "        \"ADANIPORTS.NS\",     # Adani Ports â€“ Ports, logistics\n",
    "        \"CONCOR.NS\",         # Container Corp â€“ Rail logistics\n",
    "        \"GMRINFRA.NS\",       # GMR Airports Infra â€“ Airports, urban infra\n",
    "        \"APLAPOLLO.NS\",      # Apollo Tubes â€“ Structural steel (infra input)\n",
    "    \n",
    "        # ðŸ™ï¸ Urban Infra / Smart City / Metro\n",
    "        # \"JMC.NS\",            # JMC Projects â€“ Urban infra, metros\n",
    "        \"RAJRATAN.NS\",       # Rajratan Global â€“ Tyre bead wire, industrial infra\n",
    "    \n",
    "        # ðŸ§± Materials for Infra\n",
    "        \"RAMCOCEM.NS\",       # Ramco Cement\n",
    "        \"ULTRACEMCO.NS\",     # UltraTech Cement\n",
    "        \"JKCEMENT.NS\",       # JK Cement\n",
    "        \"STLTECH.NS\",        # Sterlite Tech â€“ Optical infra for smart cities\n",
    "    ]\n",
    "    \n",
    "    metal_stocks_nse = [\n",
    "        \"TATASTEEL.NS\",      # Tata Steel â€“ Integrated steel producer\n",
    "        \"JSWSTEEL.NS\",       # JSW Steel â€“ Leading private sector steelmaker\n",
    "        \"SAIL.NS\",           # Steel Authority of India â€“ Govt-owned steel PSU\n",
    "        \"HINDALCO.NS\",       # Hindalco â€“ Aluminum & copper (Aditya Birla Group)\n",
    "        \"VEDL.NS\",           # Vedanta Ltd â€“ Diversified metals & mining\n",
    "        \"NMDC.NS\",           # NMDC â€“ Iron ore mining PSU\n",
    "        \"NATIONALUM.NS\",     # National Aluminium Co. â€“ PSU aluminum producer\n",
    "        \"JINDALSTEL.NS\",     # Jindal Steel & Power â€“ Steel & power\n",
    "        \"RATNAMANI.NS\",      # Ratnamani Metals â€“ Steel tubes & pipes\n",
    "        \"APLAPOLLO.NS\",      # APL Apollo â€“ Structural steel pipes\n",
    "        \"MOIL.NS\",           # Manganese Ore India Ltd â€“ PSU manganese miner\n",
    "        \"HINDZINC.NS\",       # Hindustan Zinc â€“ Zinc & silver mining (Vedanta)\n",
    "        \"WELCORP.NS\",        # Welspun Corp â€“ Pipes (oil & gas sector)\n",
    "        \"MASTEK.NS\",         # (Possible misclassified â€“ tech, not metals)\n",
    "        \"SHYAMMETL.NS\",      # Shyam Metalics â€“ Ferrous metals & ferroalloys\n",
    "        \"JSWISPL.NS\",        # JSW Ispat â€“ Steel products (subsidiary of JSW)\n",
    "        \"TUNGAMETAL.NS\",     # Tungabhadra Steel â€“ Small-cap alloy maker\n",
    "        \"MANAKALUCO.NS\",     # Manaksia Aluminium â€“ Non-ferrous\n",
    "        \"SANDUMA.NS\",        # Sandur Manganese â€“ Iron ore & manganese\n",
    "    ]\n",
    "    \n",
    "    gold_etf_nse  = [\n",
    "    \"GOLDBEES.NS\",     # Nippon India Gold BeES â€“ Most liquid and oldest gold ETF in India\n",
    "    \"HDFCMFGETF.NS\",   # HDFC Gold ETF â€“ Managed by HDFC Mutual Fund, well-established\n",
    "    \"GOLDIETF.NS\",     # ICICI Prudential Gold ETF â€“ Popular, low tracking error\n",
    "    \"KOTAKGOLD.NS\",    # Kotak Gold ETF â€“ Offered by Kotak Mutual Fund\n",
    "    \"SBIGETS.NS\",      # SBI Gold ETF â€“ From SBI Mutual Fund, large AUM\n",
    "    \"GOLDSHARE.NS\",    # UTI Gold ETF â€“ Managed by UTI Mutual Fund\n",
    "    \"BSLGOLDETF.NS\",   # Aditya Birla Sun Life Gold ETF â€“ Competitive expense ratio\n",
    "    \"AXISGOLD.NS\",     # Axis Gold ETF â€“ Offered by Axis Mutual Fund\n",
    "    \"QGOLDHALF.NS\",    # Quantum Gold ETF â€“ Passive, low-cost, first to offer direct plan\n",
    "    \"IDBIGOLD.NS\",     # IDBI Gold ETF â€“ From IDBI Mutual Fund\n",
    "    \"IVZINGOLD.NS\"     # Invesco India Gold ETF â€“ Managed by Invesco Mutual Fund\n",
    "    ]\n",
    "    \n",
    "    auto_stocks_nse = [\n",
    "        # ðŸš™ Passenger & Commercial Vehicles\n",
    "        \"TATAMOTORS.NS\",       # Tata Motors â€“ PVs, CVs, EVs (owns Jaguar-Land Rover)\n",
    "        \"MAHINDRA.NS\",         # Mahindra & Mahindra â€“ SUVs, tractors, EVs\n",
    "        \"MARUTI.NS\",           # Maruti Suzuki â€“ Indiaâ€™s largest passenger car maker\n",
    "        \"ASHOKLEY.NS\",         # Ashok Leyland â€“ Commercial vehicles\n",
    "        \"EICHERMOT.NS\",        # Eicher Motors â€“ Royal Enfield & trucks (VECV)\n",
    "        \"FORCEMOT.NS\",         # Force Motors â€“ Commercial vehicles\n",
    "        \"SMLISUZU.NS\",         # SML Isuzu â€“ Trucks, buses\n",
    "    \n",
    "        # ðŸ›µ Two-Wheelers & Three-Wheelers\n",
    "        \"BAJAJ-AUTO.NS\",       # Bajaj Auto â€“ Motorcycles & 3-wheelers\n",
    "        \"TVSMOTOR.NS\",         # TVS Motor â€“ 2-wheelers, electric scooters\n",
    "        \"HEROMOTOCO.NS\",       # Hero MotoCorp â€“ World's largest 2-wheeler maker\n",
    "        \"ATULAUTO.NS\",         # Atul Auto â€“ 3-wheelers\n",
    "    \n",
    "        # ðŸ”‹ EV & Battery Linked\n",
    "        \"OLECTRA.NS\",          # Olectra Greentech â€“ Electric buses\n",
    "        \"GREAVESCOT.NS\",       # Greaves Cotton â€“ EV powertrains\n",
    "        \"AMARAJABAT.NS\",       # Amara Raja Batteries\n",
    "        \"EXIDEIND.NS\",         # Exide Industries â€“ Batteries, EV tie-ups\n",
    "    \n",
    "        # ðŸ”§ Auto Ancillaries\n",
    "        \"BOSCHLTD.NS\",         # Bosch India â€“ Auto components, electronics\n",
    "        \"MOTHERSUMI.NS\",       # Samvardhana Motherson â€“ Wiring, mirrors, modules\n",
    "        \"SONA.BLW.NS\",         # Sona BLW Precision â€“ EV & ICE drivetrain\n",
    "        \"ENDURANCE.NS\",        # Endurance Tech â€“ Suspension, brakes\n",
    "        \"SCHAEFFLER.NS\",       # Schaeffler India â€“ Bearings, engine systems\n",
    "        \"VARROC.NS\",           # Varroc Engineering â€“ Lighting, EV parts\n",
    "    \n",
    "        # ðŸ›ž Tyre Manufacturers\n",
    "        \"MRF.NS\",              # MRF Ltd\n",
    "        \"APOLLOTYRE.NS\",       # Apollo Tyres\n",
    "        \"CEATLTD.NS\",          # CEAT\n",
    "        \"BALKRISIND.NS\",       # Balkrishna Industries â€“ Off-road tyres\n",
    "        \"JKTYRE.NS\",           # JK Tyre\n",
    "        \"TVSSRICHAK.NS\",       # TVS Srichakra\n",
    "    \n",
    "        # ðŸšœ Tractors & Agri Vehicles\n",
    "        \"ESCORTS.NS\"           # Escorts Kubota â€“ Tractors, railway components\n",
    "    ]\n",
    "    \n",
    "    chemical_stocks_nse = [\n",
    "        # ðŸ”¬ Specialty Chemicals\n",
    "        \"AARTIIND.NS\",       # Aarti Industries â€“ Specialty & pharma intermediates\n",
    "        \"NAVINFLUOR.NS\",     # Navin Fluorine â€“ Fluorochemicals\n",
    "        \"SRF.NS\",            # SRF Ltd â€“ Fluorochemicals, packaging films\n",
    "        \"PIIND.NS\",          # PI Industries â€“ Agrochemicals + CRAMS\n",
    "        \"FINEORG.NS\",        # Fine Organic â€“ Oleochemicals\n",
    "        \"ALKYLAMINE.NS\",     # Alkyl Amines â€“ Aliphatic amines\n",
    "        \"BALAMINES.NS\",      # Balaji Amines â€“ Amines & derivatives\n",
    "        \"DEEPAKNTR.NS\",      # Deepak Nitrite â€“ Phenol, acetone, nitrites\n",
    "        \"VINATIORGA.NS\",     # Vinati Organics â€“ ATBS, IBB (specialty chemicals)\n",
    "        \"TATACHEM.NS\",       # Tata Chemicals â€“ Soda ash, nutraceuticals\n",
    "        \"LAURUSLABS.NS\",     # Laurus Labs â€“ APIs & pharma chemicals\n",
    "        \"GUJALKALI.NS\",      # Gujarat Alkalies â€“ Caustic soda, chlorine\n",
    "        \"GHCL.NS\",           # GHCL â€“ Soda ash, textiles\n",
    "        \"CHEMPLASTS.NS\",     # Chemplast Sanmar â€“ PVC & specialty pastes\n",
    "        \"HEUBACHIND.NS\",     # Heubach Colorants (formerly Clariant) â€“ Pigments\n",
    "        \"RELCHEMQ.NS\",       # Reliance Chemotex â€“ Industrial chemicals\n",
    "        \"JUBLINGREA.NS\",     # Jubilant Ingrevia â€“ Chemicals, life science ingredients\n",
    "    \n",
    "        # ðŸŒ¾ Agrochemicals\n",
    "        \"RALLIS.NS\",         # Rallis India â€“ Tata Group, agrochemicals\n",
    "        \"BHARATRAS.NS\",      # Bharat Rasayan â€“ Pesticides, technicals\n",
    "        \"BASF.NS\",           # BASF India â€“ Global agro and industrial chemical MNC\n",
    "        \"DHANUKA.NS\",        # Dhanuka Agritech â€“ Pesticides\n",
    "        \"INSECTICID.NS\",     # Insecticides India â€“ Agrochemicals\n",
    "        \"HERANBA.NS\",        # Heranba Industries â€“ Crop protection chemicals\n",
    "    \n",
    "        # âš—ï¸ Industrial / Bulk Chemicals\n",
    "        \"DCW.NS\",            # DCW Ltd â€“ Caustic soda, PVC\n",
    "        \"TANLA.NS\",          # (Note: This is a tech stock, not chemical. Skip if mislisted.)\n",
    "        \"ALKEM.NS\",          # Alkem Labs â€“ (Mostly pharma; minor chemical exposure)\n",
    "        \"MEGH.NS\",           # Meghmani Organics â€“ Pigments, agrochemicals\n",
    "        \"KPRMILL.NS\"         # (Primarily textile; check if chemical division relevant)\n",
    "    ]\n",
    "    \n",
    "    if return_all == False:\n",
    "        if index   == 1:\n",
    "            return nifty50_stocks\n",
    "        elif index == 2:\n",
    "            return ai_stocks_nse\n",
    "        elif index == 3:\n",
    "            return defence_stocks\n",
    "        elif index == 4:\n",
    "            return pharma_stocks_nse\n",
    "        elif index == 5:\n",
    "            return energy_stocks_nse\n",
    "        elif index == 6:\n",
    "            return fmcg_stocks_nse\n",
    "        elif index == 7:\n",
    "            return banking_stocks_nse\n",
    "        elif index == 8:\n",
    "            return infra_stocks_nse\n",
    "        elif index == 9:\n",
    "            return metal_stocks_nse\n",
    "        elif index == 10:\n",
    "            return gold_etf_nse\n",
    "        elif index == 11:\n",
    "            return auto_stocks_nse\n",
    "        elif index == 12:\n",
    "            return chemical_stocks_nse\n",
    "    else:\n",
    "        stocks = list(set(nifty50_stocks + ai_stocks_nse + defence_stocks + pharma_stocks_nse + \n",
    "                          energy_stocks_nse + fmcg_stocks_nse + banking_stocks_nse + infra_stocks_nse + \n",
    "                         metal_stocks_nse + gold_etf_nse + auto_stocks_nse +  chemical_stocks_nse ))\n",
    "        return stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ae5daa-118f-4531-9a2c-7281d412722d",
   "metadata": {},
   "source": [
    "## Display top stocks\n",
    "Shortlists the top performing stocks over a period from various choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0244efa3-86aa-4c1a-951d-56c54c100fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_top_stocks(tickers, period):\n",
    "    # Download last 6 months of data\n",
    "    data = yf.download(tickers, period=period, interval=\"1d\")['Close']\n",
    "\n",
    "    # Drop columns with all NaNs (if any ticker didn't download)\n",
    "    data = data.dropna(axis=1, how='all')\n",
    "\n",
    "    # Calculate percentage return\n",
    "    returns = (data.iloc[-1] - data.iloc[0]) / data.iloc[0] * 100\n",
    "    returns = returns.sort_values(ascending=False)\n",
    "\n",
    "    # Display best performing stocks\n",
    "    print(f\"ðŸ“ˆ Best Performing Stocks in {period}:\")\n",
    "    print(returns)\n",
    "    returns.to_csv(f\"returns_{period}.csv\", header=[\"% Return\"])\n",
    "    \n",
    "    # Compute volatility\n",
    "    daily_returns = data.pct_change().dropna()\n",
    "\n",
    "    volatility = daily_returns.std() * 100  # Daily volatility in %\n",
    "    annual_volatility = daily_returns.std() * np.sqrt(252) * 100  # Annualized\n",
    "    \n",
    "    # Combine into DataFrame\n",
    "    vol_df = pd.DataFrame({\n",
    "        \"Daily Volatility (%)\": volatility.round(2),\n",
    "        \"Annualized Volatility (%)\": annual_volatility.round(2)\n",
    "    }).sort_values(by=\"Annualized Volatility (%)\", ascending=False)\n",
    "    \n",
    "    # Save to CSV\n",
    "    vol_df.to_csv(f\"Files//volatility_{period}.csv\")\n",
    "    \n",
    "    # Print\n",
    "    print(f\"ðŸ“Š Volatility (period: {period}) saved to 'volatility_{period}.csv'\")\n",
    "    print(vol_df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get top 10 performers\n",
    "    top_10 = returns.sort_values(ascending=False).head(10).index.tolist()\n",
    "\n",
    "    # Normalize data for top 10\n",
    "    normalized = data[top_10] / data[top_10].iloc[0] * 100\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for col in normalized.columns:\n",
    "        plt.plot(normalized.index, normalized[col], label=col)\n",
    "\n",
    "    plt.title(f\"Top 10 Performing Stocks ({period})\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Normalized Price (Start = 100)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot 10 most stable stocks\n",
    "    top_stable = vol_df.tail(10)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(top_stable.index, top_stable[\"Annualized Volatility (%)\"], color='teal')\n",
    "    plt.xlabel(\"Annualized Volatility (%)\")\n",
    "    plt.title(\"10 Most Stable Stocks (Lowest Volatility)\")\n",
    "    plt.gca().invert_yaxis()  # lowest volatility at top\n",
    "    plt.grid(axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # --- Combine into DataFrame ---\n",
    "    df = pd.DataFrame({\n",
    "        \"Returns (%)\": returns.round(2),\n",
    "        \"Annualized Volatility (%)\": annual_volatility.round(2)\n",
    "    })\n",
    "    \n",
    "    # --- Sharpe Ratio (returns / risk) ---\n",
    "    df[\"Sharpe Ratio\"] = (df[\"Returns (%)\"] / df[\"Annualized Volatility (%)\"]).round(2)\n",
    "    \n",
    "    # --- Selection Criteria ---\n",
    "    median_vol = df[\"Annualized Volatility (%)\"].median()\n",
    "    \n",
    "    # Top 5 by Sharpe\n",
    "    top_sharpe = df.sort_values(by=\"Sharpe Ratio\", ascending=False).head(5)\n",
    "    \n",
    "    # High-return, low-volatility filter\n",
    "    filtered = df[(df[\"Returns (%)\"] > 5) & (df[\"Annualized Volatility (%)\"] < median_vol)]\n",
    "    \n",
    "    # --- Save Results ---\n",
    "    df.to_csv(f\"Files//full_analysis_{period}.csv\")\n",
    "    top_sharpe.to_csv(f\"top_sharpe_{period}.csv\")\n",
    "    filtered.to_csv(f\"Files//high_return_low_volatility_{period}.csv\")\n",
    "    \n",
    "    # --- Display Output ---\n",
    "    print(f\"\\nâœ… Full analysis saved to 'full_analysis_{period}.csv'\")\n",
    "    print(\"\\nðŸ“Š Top 5 by Sharpe Ratio:\")\n",
    "    print(top_sharpe)\n",
    "    \n",
    "    print(\"\\nðŸ“‰ High-return, Low-volatility Picks:\")\n",
    "    print(filtered)\n",
    "    \n",
    "    # Top 3 by Sharpe and Returns\n",
    "    top_sharpe_tickers = df.sort_values(by=\"Sharpe Ratio\", ascending=False).head(3).index\n",
    "    top_return_tickers = df.sort_values(by=\"Returns (%)\", ascending=False).head(3).index\n",
    "    \n",
    "    # Assign colors\n",
    "    colors = []\n",
    "    for ticker in df.index:\n",
    "        if ticker in top_sharpe_tickers:\n",
    "            colors.append('green')\n",
    "        elif ticker in top_return_tickers:\n",
    "            colors.append('blue')\n",
    "        else:\n",
    "            colors.append('gray')\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df[\"Sharpe Ratio\"], df[\"Returns (%)\"], c=colors, s=100, edgecolors='black')\n",
    "    \n",
    "    # Annotate each point\n",
    "    for ticker in df.index:\n",
    "        plt.annotate(ticker, \n",
    "                     (df.loc[ticker, \"Sharpe Ratio\"], df.loc[ticker, \"Returns (%)\"]),\n",
    "                     textcoords=\"offset points\", xytext=(5, 5), ha='left', fontsize=9)\n",
    "    \n",
    "    # Labels and styling\n",
    "    plt.xlabel(\"Sharpe Ratio (Return / Volatility)\")\n",
    "    plt.ylabel(\"Returns (%)\")\n",
    "    plt.title(\"Sharpe Ratio vs Returns (Top Performers Highlighted)\")\n",
    "    plt.axhline(0, color='gray', linestyle='--', linewidth=0.7)\n",
    "    plt.axvline(0, color='gray', linestyle='--', linewidth=0.7)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0529e0-8826-40e6-aa0a-f106e0c9a4e0",
   "metadata": {},
   "source": [
    "## Optimise portfolio\n",
    "Fetch data from varios stocks and allocates the amount to invest as per the user budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa48c15-0f01-44e5-a6cb-11298b40bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise_portfolio(all_tickers, period, ticker_type):\n",
    "    # ----------------- USER INPUTS -------------------\n",
    "    \n",
    "    budget = float(input(\"ðŸ’° Enter your total investment budget (e.g., 100000): \"))\n",
    "\n",
    "    # ----------------- FETCH PRICE DATA -------------------\n",
    "    data = yf.download(all_tickers, period=period)['Close']\n",
    "    data = data.dropna(axis=1, thresh=len(data) * 0.9)  # remove stocks with missing data\n",
    "    returns = data.pct_change().dropna()\n",
    "    \n",
    "    # ----------------- SHARPE RATIO CALC -------------------\n",
    "    annual_returns = returns.mean() * 252\n",
    "    annual_volatility = returns.std() * np.sqrt(252)\n",
    "    sharpe_ratio = annual_returns / annual_volatility\n",
    "    \n",
    "    top5_tickers = sharpe_ratio.sort_values(ascending=False).head(5).index.tolist()\n",
    "    print(\"\\nðŸ“ˆ Top 5 Stocks by Sharpe Ratio:\")\n",
    "    print(top5_tickers)\n",
    "    \n",
    "    # ----------------- OPTIMIZATION -------------------\n",
    "    top_returns = returns[top5_tickers]\n",
    "    \n",
    "    def portfolio_perf(weights):\n",
    "        ret = np.sum(top_returns.mean() * weights) * 252\n",
    "        vol = np.sqrt(np.dot(weights.T, np.dot(top_returns.cov() * 252, weights)))\n",
    "        sharpe = ret / vol\n",
    "        return ret, vol, sharpe\n",
    "    \n",
    "    def neg_sharpe(weights):\n",
    "        return -portfolio_perf(weights)[2]\n",
    "    \n",
    "    num_assets = len(top5_tickers)\n",
    "    bounds = tuple((0, 1) for _ in range(num_assets))\n",
    "    constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}\n",
    "    init_guess = [1/num_assets] * num_assets\n",
    "    \n",
    "    result = minimize(neg_sharpe, init_guess, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    weights = result.x\n",
    "    \n",
    "    # ----------------- ALLOCATION BASED ON BUDGET -------------------\n",
    "    latest_prices = data[top5_tickers].iloc[-1]\n",
    "    allocation_df = pd.DataFrame({\n",
    "        'Ticker': top5_tickers,\n",
    "        'Weight': weights,\n",
    "        'Latest Price': latest_prices\n",
    "    })\n",
    "    \n",
    "    allocation_df['Allocated Amount'] = allocation_df['Weight'] * budget\n",
    "    allocation_df['Shares to Buy'] = (allocation_df['Allocated Amount'] / allocation_df['Latest Price']).astype(int)\n",
    "    allocation_df['Actual Invested'] = allocation_df['Shares to Buy'] * allocation_df['Latest Price']\n",
    "    if ticker_type == 'all':\n",
    "        allocation_df.to_csv('Files//Optimised_portfolio_all_sectors.csv')\n",
    "    elif ticker_type == 'sector':\n",
    "        allocation_df.to_csv('Files//Optimised_portfolio_specific_sector.csv')\n",
    "    elif ticker_type == 'user':\n",
    "        allocation_df.to_csv('Files//Optimised_portfolio_specific_sector.csv')\n",
    "    # ----------------- SUMMARY -------------------\n",
    "    total_invested = allocation_df['Actual Invested'].sum()\n",
    "    remaining_cash = budget - total_invested\n",
    "    \n",
    "    print(\"\\nðŸ“Š Optimized Allocation:\")\n",
    "    print(allocation_df[['Ticker', 'Weight', 'Shares to Buy', 'Actual Invested']])\n",
    "    \n",
    "    print(f\"\\nâœ… Total Invested: â‚¹{total_invested:.2f}\")\n",
    "    print(f\"ðŸ’° Remaining Cash: â‚¹{remaining_cash:.2f}\")\n",
    "    \n",
    "    # ----------------- PIE CHART -------------------\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.pie(allocation_df['Actual Invested'], labels=allocation_df['Ticker'],\n",
    "            autopct='%1.1f%%', startangle=90)\n",
    "    plt.title(\"Investment Allocation (Top 5 Sharpe Stocks)\")\n",
    "    plt.tight_layout()\n",
    "    if ticker_type == 'all':\n",
    "        plt.savefig('Files//Investment_Allocation_all_sectors.png')\n",
    "    elif ticker_type == 'sector':\n",
    "        plt.savefig('Files//Investment_Allocation__specific_sector.png')\n",
    "    elif ticker_type == 'user':\n",
    "        plt.savefig('Files//Investment_Allocation_user.png')\n",
    "    plt.show()\n",
    "    return allocation_df, total_invested, remaining_cash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa6f1ab-3968-4899-aa36-4ea45edf07ab",
   "metadata": {},
   "source": [
    "## Identify top stocks as per user requirement\n",
    "1. All stocks\n",
    "2. Promps for a sector and selects top performing stocks for that sector\n",
    "3. User shortlisted stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f3965f-ccde-4fdc-9081-0d2107e60255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Identify top stocks\n",
    "# =============================================================================\n",
    "# List of NSE stock tickers\n",
    "if analyze_stocks == '1':\n",
    "    tickers_all = sector_stocks(0, return_all = True)\n",
    "    display_top_stocks(tickers_all, period)\n",
    "   \n",
    "\n",
    "    # =============================================================================\n",
    "    # Optimise portfolio for all the sectors\n",
    "    # =============================================================================\n",
    "    allocation_df, total_invested, remaining_cash = optimise_portfolio(tickers_all,ticker_type = 'all',period = period)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Prompt for sector\n",
    "# =============================================================================\n",
    "elif analyze_stocks == '2':\n",
    "    sectors = ['NIFTY50', 'AI', 'DEFENSE', 'PHARMA', 'ENERGY', 'FMCG', 'BANKING', 'INFRA', 'METALS', 'GOLD ETF','AUTO', 'CHEMICALS']\n",
    "    print(\"Choose a sector:\")\n",
    "    for i, prompt in enumerate(sectors, start=1):\n",
    "        print(f\"{i}. {prompt}\")\n",
    "    sector_choice = int(input(f\"Enter your sector choice (1-{len(sectors)}): \"))    \n",
    "    if 1 <= sector_choice <= len(sectors):\n",
    "        selected_prompt = sectors[sector_choice - 1]\n",
    "        print(f\"\\nYou selected: {selected_prompt} Stocks\")\n",
    "    else:\n",
    "        print(\"Invalid choice!\")\n",
    "    \n",
    "    sel_sect_tickers = sector_stocks(sector_choice)\n",
    "    display_top_stocks(sel_sect_tickers, period=period)\n",
    "    # =============================================================================\n",
    "    # Optimise portfolio for given sector\n",
    "    # =============================================================================\n",
    "    allocation_df_sect, total_invested_sect, remaining_cash_sect = optimise_portfolio(sel_sect_tickers,ticker_type='sector',period = period)\n",
    "\n",
    "    # =============================================================================\n",
    "    # Prompt for a particular stock in a sector\n",
    "    # =============================================================================\n",
    "    print(\"Choose a sector:\")\n",
    "    for i, prompt in enumerate(sel_sect_tickers, start=1):\n",
    "        print(f\"{i}. {prompt.split('.')[0]}\")\n",
    "    stock_choice = int(input(f\"Enter your stock choice (1-{len(sel_sect_tickers)}): \"))    \n",
    "    if 1 <= stock_choice <= len(sel_sect_tickers):\n",
    "        selected_prompt = sel_sect_tickers[stock_choice - 1]\n",
    "        print(f\"\\nYou selected: {selected_prompt.split('.')[0]}\")\n",
    "    else:\n",
    "        print(\"Invalid choice!\")\n",
    "    tickers = [selected_prompt]\n",
    "\n",
    "elif analyze_stocks == '3': \n",
    "    # =============================================================================\n",
    "    # Optimise portfolio for user specific stocks\n",
    "    # =============================================================================\n",
    "    user_stocks = ['HAL.NS','MAZDOCK.NS','COCHINSHIP.NS','IDEAFORGE.NS','PARAS.NS','M&M.NS']\n",
    "    allocation_df_user, total_invested_user, remaining_cash_user = optimise_portfolio(user_stocks,ticker_type='user',period = period)\n",
    "\n",
    "    for i, prompt in enumerate(user_stocks, start=1):\n",
    "        print(f\"{i}. {prompt.split('.')[0]}\")\n",
    "    stock_choice = int(input(f\"Enter your stock choice (1-{len(user_stocks)}): \"))    \n",
    "    if 1 <= stock_choice <= len(user_stocks):\n",
    "        selected_prompt = user_stocks[stock_choice - 1]\n",
    "        print(f\"\\nYou selected: {selected_prompt.split('.')[0]}\")\n",
    "    else:\n",
    "        print(\"Invalid choice!\")\n",
    "    tickers = [selected_prompt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e67da5d-7a69-43b5-a8f9-e8bf8c635cdf",
   "metadata": {},
   "source": [
    "## Plot moving average of the stock\n",
    "- Plot 50 day and 200 day time average data\n",
    "- Show crossover dates\n",
    "- Golden Cross = 50_DMA crosses above 200_DMA â†’ Signal changes from -1 to 1 (Crossover = 2)\n",
    "- Death Cross = 50_DMA crosses below 200_DMA â†’ Signal changes from 1 to -1 (Crossover = -2)\n",
    "- Analyze correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca992a8-ecfd-4929-b902-347bf91c91cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(tickers):\n",
    "    df = yf.download(tickers, period=\"5y\", interval=\"1d\")\n",
    "    discription = df.describe()\n",
    "\n",
    "    # Calculate 50 DMA and 200 DMA\n",
    "    df['DMA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    df['DMA_200'] = df['Close'].rolling(window=200).mean()\n",
    "\n",
    "    # Plot closing prices vs 50DMA and 200DMA\n",
    "    sns.set_style('darkgrid')\n",
    "    plt.figure(figsize = (7,5), dpi = 150)\n",
    "    plt.title(f'Closing Prices vs 50 DMA & 200 DMA for {tickers[0].split(\".\")[0]}')\n",
    "    plt.plot(df['Close'],label = 'Closing Price')\n",
    "    plt.plot(df['DMA_50'],label = 'DMA_50')\n",
    "    plt.plot(df['DMA_200'],label = 'DMA_200')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'Files//Closing_Prices_{tickers[0].split(\".\")[0]}.png')\n",
    "\n",
    "    # Create Plotly figure\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df['Close'].to_numpy().flatten(), mode='lines', name='Closing Price'))\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df['DMA_50'].to_numpy().flatten(), mode='lines', name='DMA_50'))\n",
    "    fig.add_trace(go.Scatter(x=df.index, y=df['DMA_200'].to_numpy().flatten(), mode='lines', name='DMA_200'))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title={\n",
    "        'text': f'Closing Prices vs 50 DMA & 200 DMA for {tickers[0].split(\".\")[0]}',\n",
    "        'x': 0.5,  # Center the title\n",
    "        'xanchor': 'center'\n",
    "        },\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Price',\n",
    "        legend_title='Legend',\n",
    "        template='plotly_white',\n",
    "        font=dict(\n",
    "        family='Times New Roman',\n",
    "        size=14\n",
    "        ),\n",
    "        autosize=True,\n",
    "        height=800,\n",
    "        width=1400\n",
    "    )\n",
    "    fig.write_html(f'Files//Closing_Prices_{tickers[0].split(\".\")[0]}.html', auto_open=True)\n",
    "\n",
    "    # Analyze correlation\n",
    "    plt.figure(figsize = (7,7), dpi = 150)\n",
    "    sns.heatmap(df.corr(),annot=True)\n",
    "\n",
    "    # Plot distplot\n",
    "    sns.set_style('darkgrid')\n",
    "    plt.figure(figsize = (7,5), dpi = 150)\n",
    "    plt.title('Distplot 50DMA')\n",
    "    sns.distplot(df['DMA_50'])\n",
    "\n",
    "    sns.set_style('darkgrid')\n",
    "    plt.figure(figsize = (7,5), dpi = 150)\n",
    "    plt.title('Distplot 200DMA')\n",
    "    sns.distplot(df['DMA_200'])\n",
    "\n",
    "\n",
    "    df['Signal'] = 0\n",
    "    df.loc[df['DMA_50'] > df['DMA_200'], 'Signal'] = 1\n",
    "    df.loc[df['DMA_50'] < df['DMA_200'], 'Signal'] = -1\n",
    "    # Detect crossover points\n",
    "    df['Crossover'] = df['Signal'].diff()\n",
    "    # Show crossover dates\n",
    "    crossovers = df[df['Crossover'].abs() == 2]  # 2 = change from 1 to -1 or vice versa\n",
    "\n",
    "    # Golden Cross = 50_DMA crosses above 200_DMA â†’ Signal changes from -1 to 1 (Crossover = 2)\n",
    "    # Death Cross = 50_DMA crosses below 200_DMA â†’ Signal changes from 1 to -1 (Crossover = -2)\n",
    "\n",
    "    for date, row in crossovers.iterrows():\n",
    "        if row['Crossover'].to_numpy()[0] == 2:\n",
    "            print(f\"ðŸ”” Golden Cross on {date.date()} â€” Possible Uptrend!\")\n",
    "        elif row['Crossover'].to_numpy()[0] == -2:\n",
    "            print(f\"âš ï¸ Death Cross on {date.date()}  â€” Possible Downtrend!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850a90fb-8d70-438e-a1ec-496af2f54184",
   "metadata": {},
   "source": [
    "## Identify support and resistance\n",
    "- Identify local minima and maxima for support and resistance\n",
    "- Plot support and resistance lines\n",
    "- \n",
    "            ðŸ“‰ Black line: Daily close price\n",
    "\n",
    "            ðŸŸ¢ Dotted green line: Support trendline\n",
    "            \n",
    "            ðŸ”´ Dotted red line: Resistance trendline\n",
    "            \n",
    "            â¬†ï¸ Green triangles: Local support points\n",
    "            \n",
    "            ðŸ”» Red triangles: Local resistance points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ab208f-1384-49f8-ac2e-55f6b54d7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_resistance(ticker):\n",
    "    df = yf.download(ticker, period=\"6mo\", interval=\"1d\")\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # Identify local minima and maxima for support and resistance\n",
    "    n = 5  # Number of points to consider for local extrema\n",
    "    # Find extrema\n",
    "    min_idx = argrelextrema(df['Low'].values, np.less_equal, order=n)[0]\n",
    "    max_idx = argrelextrema(df['High'].values, np.greater_equal, order=n)[0]\n",
    "    \n",
    "    # Fill NaN initially\n",
    "    df['min'] = np.nan\n",
    "    df['max'] = np.nan\n",
    "    \n",
    "    # âœ… Use iloc for position-based assignment\n",
    "    df.iloc[min_idx, df.columns.get_loc('min')] = df.iloc[min_idx, df.columns.get_loc('Low')]\n",
    "    df.iloc[max_idx, df.columns.get_loc('max')] = df.iloc[max_idx, df.columns.get_loc('High')]\n",
    "    \n",
    "    df1 = df.copy()\n",
    "    # Remove NaN for support and resistance lines\n",
    "    df1.columns = [''.join(col) if isinstance(col, tuple) else col for col in df.columns]\n",
    "    support_points = df1.dropna(subset=['min'])\n",
    "    resistance_points = df1.dropna(subset=['max'])\n",
    "    \n",
    "    # Initialize candlestick chart\n",
    "    fig = go.Figure(data=[go.Candlestick(\n",
    "        x=df.index,\n",
    "        open=df['Open'],\n",
    "        high=df['High'],\n",
    "        low=df['Low'],\n",
    "        close=df['Close'],\n",
    "        name=\"Candlestick\"\n",
    "    )])\n",
    "    \n",
    "    # Add support line\n",
    "    if len(support_points) >= 2:\n",
    "        support_line = np.polyfit(support_points.index.map(pd.Timestamp.toordinal), support_points['min'], 1)\n",
    "        support_trend = np.poly1d(support_line)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df.index,\n",
    "            y=support_trend(df.index.map(pd.Timestamp.toordinal)),\n",
    "            mode='lines',\n",
    "            line=dict(color='green', dash='dash'),\n",
    "            name='Support Trendline'\n",
    "        ))\n",
    "    \n",
    "    # Add resistance line\n",
    "    if len(resistance_points) >= 2:\n",
    "        resistance_line = np.polyfit(resistance_points.index.map(pd.Timestamp.toordinal), resistance_points['max'], 1)\n",
    "        resistance_trend = np.poly1d(resistance_line)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df.index,\n",
    "            y=resistance_trend(df.index.map(pd.Timestamp.toordinal)),\n",
    "            mode='lines',\n",
    "            line=dict(color='red', dash='dash'),\n",
    "            name='Resistance Trendline'\n",
    "        ))\n",
    "    \n",
    "    # Convert dates to ordinal for fitting\n",
    "    x_dates = df.index.map(pd.Timestamp.toordinal)\n",
    "    \n",
    "    # Support trendline\n",
    "    if len(support_points) >= 2:\n",
    "        support_fit = np.polyfit(support_points.index.map(pd.Timestamp.toordinal), support_points['min'], 1)\n",
    "        support_trend = np.poly1d(support_fit)\n",
    "        support_line = support_trend(x_dates)\n",
    "    else:\n",
    "        support_line = [np.nan] * len(df)\n",
    "    \n",
    "    # Resistance trendline\n",
    "    if len(resistance_points) >= 2:\n",
    "        resistance_fit = np.polyfit(resistance_points.index.map(pd.Timestamp.toordinal), resistance_points['max'], 1)\n",
    "        resistance_trend = np.poly1d(resistance_fit)\n",
    "        resistance_line = resistance_trend(x_dates)\n",
    "    else:\n",
    "        resistance_line = [np.nan] * len(df)\n",
    "    \n",
    "    # --- Step 5: Plot everything ---\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(df.index, df['Close'], label='Close', color='black')\n",
    "    plt.scatter(df.index, df['min'], label='Support Points', color='green', marker='^')\n",
    "    plt.scatter(df.index, df['max'], label='Resistance Points', color='red', marker='v')\n",
    "    \n",
    "    # Add trendlines\n",
    "    plt.plot(df.index, support_line, color='green', linestyle='--', label='Support Line')\n",
    "    plt.plot(df.index, resistance_line, color='red', linestyle='--', label='Resistance Line')\n",
    "    \n",
    "    \n",
    "    plt.title(f\"Support and Resistance Trendlines - {ticker[0].split('.')[0]}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"Files//Support_Resistance_Trendlines_{ticker[0].split('.')[0]}.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f001cb-5431-4c66-b655-ba2e3c469c9f",
   "metadata": {},
   "source": [
    "## Analyze stock us undervalued/overvalued\n",
    "- The Relative Strength Index (RSI) is a technical indicator that measures the magnitude of recent price changes to evaluate overbought or oversold conditions in the price of a stock or other asset.\n",
    "-         RSI Value\t      Signal\n",
    "          ---------------------------\n",
    "          >70\t            Overbought\n",
    "          <30                Oversold\n",
    "          45â€“55\t          Neutral / Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5282929-796d-47af-bea9-d43015d1233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def RSI(ticker):\n",
    "    df = yf.download(ticker, period=\"6mo\", interval=\"1d\")\n",
    "    df = df.reset_index()\n",
    "    df.dropna(inplace=True)\n",
    "    # Compute daily price change ---\n",
    "    delta = df['Close'].diff()\n",
    "    # Separate gains and losses ---\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    \n",
    "    # Compute exponential moving average (recommended for RSI) ---\n",
    "    period = 14\n",
    "    avg_gain = gain.rolling(window=period, min_periods=period).mean()\n",
    "    avg_loss = loss.rolling(window=period, min_periods=period).mean()\n",
    "\n",
    "    # Use exponential average (Wilder's method)\n",
    "    avg_gain = avg_gain.ewm(alpha=1/period, min_periods=period, adjust=False).mean()\n",
    "    avg_loss = avg_loss.ewm(alpha=1/period, min_periods=period, adjust=False).mean()\n",
    "    \n",
    "    # --- Step 5: Calculate RS and RSI ---\n",
    "    rs = avg_gain / avg_loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    \n",
    "    # --- Step 6: Plot RSI ---\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(df['Date'], df['RSI'], label='RSI', color='orange')\n",
    "    plt.axhline(70, color='red', linestyle='--', label='Overbought (70)')\n",
    "    plt.axhline(30, color='green', linestyle='--', label='Oversold (30)')\n",
    "    plt.title(f\"RSI - {ticker[0]}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"RSI\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"Files//RSI_{ticker[0]}.png\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a6059e-a5ff-42fa-ae5a-aaebdef05005",
   "metadata": {},
   "source": [
    "## Intraday signals\n",
    "Get intraday signals\n",
    "- EMA\n",
    "- RSI14\n",
    "- MACD\n",
    "- VWAP & Bollinger Bands alerts\n",
    "- Generate Buy/Sell signals based on EMA crossover\n",
    "- Latest Signals and Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cabb37-9571-4bad-b17f-0c9dbfd9050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intraday(ticker):\n",
    "    \n",
    "    # --- 1. Get intraday data ---\n",
    "    df = yf.download(ticker, period=\"1d\", interval=\"5m\")\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    # --- 2. Compute Indicators ---\n",
    "    \n",
    "    # EMA\n",
    "    df['EMA_9'] = df['Close'].ewm(span=9, adjust=False).mean()\n",
    "    df['EMA_21'] = df['Close'].ewm(span=21, adjust=False).mean()\n",
    "    \n",
    "    # RSI (14)\n",
    "    delta = df['Close'].diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    avg_gain = gain.rolling(14).mean()\n",
    "    avg_loss = loss.rolling(14).mean()\n",
    "    rs = avg_gain / avg_loss\n",
    "    df['RSI_14'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # MACD\n",
    "    ema12 = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = ema12 - ema26\n",
    "    df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    \n",
    "    # VWAP\n",
    "    df['Typical_Price'] = (df['High'] + df['Low'] + df['Close']) / 3\n",
    "    df['Cum_TP_Volume'] = (df['Typical_Price'].to_numpy() * df['Volume'].to_numpy().flatten()).cumsum()\n",
    "    df['Cum_Volume'] = df['Volume'].cumsum()\n",
    "    df['VWAP'] = df['Cum_TP_Volume'] / df['Cum_Volume']\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    df['BB_Middle'] = df['Close'].rolling(window=20).mean()\n",
    "    df['BB_Upper'] = df['BB_Middle'].to_numpy()+(2 * df['Close'].rolling(window=20).std()).to_numpy().flatten()\n",
    "    df['BB_Lower'] = df['BB_Middle'].to_numpy()-(2 * df['Close'].rolling(window=20).std()).to_numpy().flatten()\n",
    "    \n",
    "    # --- Generate Buy/Sell signals based on EMA crossover ---\n",
    "    df['Signal_EMA'] = np.where((df['EMA_9'] > df['EMA_21']) & (df['EMA_9'].shift(1) <= df['EMA_21'].shift(1)), 'Buy',\n",
    "                         np.where((df['EMA_9'] < df['EMA_21']) & (df['EMA_9'].shift(1) >= df['EMA_21'].shift(1)), 'Sell', ''))\n",
    "    \n",
    "    # --- RSI signals ---\n",
    "    df['Signal_RSI'] = np.where(df['RSI_14'] < 30, 'Buy (RSI Oversold)',\n",
    "                         np.where(df['RSI_14'] > 70, 'Sell (RSI Overbought)', ''))\n",
    "    # --- VWAP and Bollinger Band alerts ---\n",
    "    df['Alert_VWAP'] = np.where(df['Close'].to_numpy().flatten() > df['VWAP'].to_numpy(), 'Above VWAP', \n",
    "                         np.where(df['Close'].to_numpy().flatten() < df['VWAP'].to_numpy(), 'Below VWAP', ''))\n",
    "    df['Alert_BB'] = np.where(df['Close'].to_numpy().flatten() > df['BB_Upper'].to_numpy().flatten(), 'Touching Upper BB',\n",
    "                       np.where(df['Close'].to_numpy().flatten() < df['BB_Lower'].to_numpy().flatten(), 'Touching Lower BB', ''))\n",
    "    \n",
    "    # --- Display last signals ---\n",
    "    latest_signals = df[['Close', 'EMA_9', 'EMA_21', 'RSI_14', 'VWAP', 'BB_Upper', 'BB_Lower',\n",
    "                         'Signal_EMA', 'Signal_RSI', 'Alert_VWAP', 'Alert_BB']].dropna().tail(10)\n",
    "    \n",
    "    print(\"\\nðŸ”” Latest Signals and Alerts:\")\n",
    "    print(latest_signals)\n",
    "    \n",
    "    # --- 3. Plotting ---\n",
    "    \n",
    "    plt.figure(figsize=(16, 10))\n",
    "    \n",
    "    # --- Subplot 1: Price + EMA + VWAP + Bollinger Bands ---\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(df.index, df['Close'], label='Close', color='black')\n",
    "    plt.plot(df.index, df['EMA_9'], label='EMA 9', color='blue')\n",
    "    plt.plot(df.index, df['EMA_21'], label='EMA 21', color='red')\n",
    "    plt.plot(df.index, df['VWAP'], label='VWAP', color='orange', linestyle='--')\n",
    "    plt.plot(df.index, df['BB_Upper'], label='BB Upper', color='green', linestyle='--', alpha=0.4)\n",
    "    plt.plot(df.index, df['BB_Lower'], label='BB Lower', color='green', linestyle='--', alpha=0.4)\n",
    "    plt.fill_between(df.index, df['BB_Upper'], df['BB_Lower'], color='green', alpha=0.1)\n",
    "    plt.title(f\"{ticker}[0] - Intraday Indicators\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    # --- Subplot 2: RSI ---\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(df.index, df['RSI_14'], label='RSI (14)', color='purple')\n",
    "    plt.axhline(70, color='red', linestyle='--', label='Overbought')\n",
    "    plt.axhline(30, color='green', linestyle='--', label='Oversold')\n",
    "    plt.title(\"RSI\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    # --- Subplot 3: MACD ---\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(df.index, df['MACD'], label='MACD', color='blue')\n",
    "    plt.plot(df.index, df['Signal'], label='Signal Line', color='orange')\n",
    "    plt.fill_between(df.index, df['MACD'] - df['Signal'], color='gray', alpha=0.2)\n",
    "    plt.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "    plt.title(\"MACD\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"Files//{ticker[0]} - Intraday Indicators.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # --- Optional: Plot Close price with Buy/Sell points (EMA crossover) ---\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(df.index, df['Close'], label='Close Price', color='black')\n",
    "    plt.plot(df.index, df['EMA_9'], label='EMA 9', color='blue', alpha=0.6)\n",
    "    plt.plot(df.index, df['EMA_21'], label='EMA 21', color='red', alpha=0.6)\n",
    "    \n",
    "    # Mark buy/sell points\n",
    "    buy_signals = df[df['Signal_EMA'] == 'Buy']\n",
    "    sell_signals = df[df['Signal_EMA'] == 'Sell']\n",
    "    plt.scatter(buy_signals.index, buy_signals['Close'], marker='^', color='green', label='Buy Signal', s=100)\n",
    "    plt.scatter(sell_signals.index, sell_signals['Close'], marker='v', color='red', label='Sell Signal', s=100)\n",
    "    \n",
    "    plt.title(f\"{ticker} - Intraday Signals\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f5a88a-22e9-469f-afbc-b5dafb9eefcf",
   "metadata": {},
   "source": [
    "## Predict next 7 day values \n",
    "- Used  Long Short-Term Memory (LSTM) Deep learning algorithm to predict the closing price for next 7 days. Unlike standard RNNs, LSTMs can remember information for long periods because they have a cell state and gates (input, forget, and output gates) that control the flow of information.\n",
    "- 7-Day Forecast with Buy/Sell Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a6b6c-4e7d-432b-abc8-fcda39f4afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future_values(ticker):\n",
    "    df = yf.download(ticker, period='1y')[['Close', 'Volume']].dropna()\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    # --- 1. Preprocess Data ---\n",
    "    df = yf.download(ticker, period='1y')\n",
    "    df['SMA_20'] = df['Close'].rolling(20).mean()\n",
    "    df['SMA_50'] = df['Close'].rolling(50).mean()\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    features = ['Close', 'Volume', 'SMA_20', 'SMA_50']\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(df[features])\n",
    "    \n",
    "    # --- 2. Prepare Sequences ---\n",
    "    sequence_length = 60\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(sequence_length, len(scaled_data)):\n",
    "        X.append(scaled_data[i-sequence_length:i])\n",
    "        y.append(scaled_data[i][0])  # Close\n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    # --- 3. Define LSTM with Dropout Enabled at Inference ---\n",
    "    def create_mc_dropout_model(input_shape):\n",
    "        inputs = Input(shape=input_shape)\n",
    "        x = LSTM(64, return_sequences=True)(inputs)\n",
    "        x = Dropout(0.3)(x, training=True)  # Dropout active during inference\n",
    "        x = LSTM(64)(x)\n",
    "        x = Dropout(0.3)(x, training=True)\n",
    "        outputs = Dense(1)(x)\n",
    "        model = Model(inputs, outputs)\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        return model\n",
    "    \n",
    "    model = create_mc_dropout_model((X.shape[1], X.shape[2]))\n",
    "    model.fit(X, y, epochs=25, batch_size=32, verbose=1)\n",
    "    \n",
    "    # --- 4. Recursive Forecast with MC Dropout ---\n",
    "    n_days = 7\n",
    "    n_simulations = 30\n",
    "    last_seq = scaled_data[-sequence_length:]\n",
    "    future_predictions = []\n",
    "    \n",
    "    for day in range(n_days):\n",
    "        preds = []\n",
    "        for _ in range(n_simulations):\n",
    "            input_seq = last_seq.reshape(1, sequence_length, len(features))\n",
    "            pred = model.predict(input_seq, verbose=0)[0][0]\n",
    "            preds.append(pred)\n",
    "    \n",
    "        mean_pred = np.mean(preds)\n",
    "        std_pred = np.std(preds)\n",
    "    \n",
    "        # Inverse scale Close price\n",
    "        dummy = np.zeros((1, len(features)))\n",
    "        dummy[0][0] = mean_pred\n",
    "        price = scaler.inverse_transform(dummy)[0][0]\n",
    "    \n",
    "        # Confidence ~ low std â†’ high confidence\n",
    "        confidence = max(0.0, 1 - std_pred * 10)  # crude scale from 1 to 0\n",
    "    \n",
    "        future_predictions.append((price, confidence))\n",
    "    \n",
    "        # Add the predicted row back into the sequence\n",
    "        new_row = last_seq[-1].copy()\n",
    "        new_row[0] = mean_pred\n",
    "        last_seq = np.vstack([last_seq[1:], new_row])\n",
    "    \n",
    "    # --- 5. Display Results ---\n",
    "    future_dates = pd.date_range(start=df.index[-1] + pd.Timedelta(days=1), periods=n_days)\n",
    "    \n",
    "    forecast_df = pd.DataFrame({\n",
    "        'Date': future_dates,\n",
    "        'Predicted_Close': [p[0] for p in future_predictions],\n",
    "        'Confidence (0-1)': [round(p[1], 3) for p in future_predictions]\n",
    "    })\n",
    "    \n",
    "    print(forecast_df)\n",
    "    forecast_df.to_csv(f'Files//Forecasted_vales_{ticker[0].split(\".\")[0]}.csv')\n",
    "    \n",
    "    # --- 6. Plot ---\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df.index[-60:], df['Close'].iloc[-60:], label='Historical', linewidth=2)\n",
    "    plt.plot(forecast_df['Date'], forecast_df['Predicted_Close'], marker='o', linestyle='--', color='orange', label='Forecast')\n",
    "    plt.fill_between(forecast_df['Date'],\n",
    "                     forecast_df['Predicted_Close'] * (1 - 0.05),\n",
    "                     forecast_df['Predicted_Close'] * (1 + 0.05),\n",
    "                     alpha=0.2, color='orange', label='Â±5% band')\n",
    "    plt.title(f'{ticker[0].split(\".\")[0]} - Next 7 Day Price Forecast')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Predicted Close Price (INR)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{ticker[0].split(\".\")[0]}_Next7_Day_Price_Forecast.png')\n",
    "    plt.show()\n",
    "    \n",
    "    threshold_pct = 0.005  # 0.5%\n",
    "    confidence_threshold = 0.85\n",
    "    \n",
    "    signals = []\n",
    "    for i in range(1, len(forecast_df)):\n",
    "        prev_price = forecast_df.loc[i-1, 'Predicted_Close']\n",
    "        curr_price = forecast_df.loc[i, 'Predicted_Close']\n",
    "        confidence = forecast_df.loc[i, 'Confidence (0-1)']\n",
    "        \n",
    "        price_change_pct = (curr_price - prev_price) / prev_price\n",
    "        \n",
    "        if (price_change_pct > threshold_pct) and (confidence >= confidence_threshold):\n",
    "            signals.append('BUY')\n",
    "        elif (price_change_pct < -threshold_pct) and (confidence >= confidence_threshold):\n",
    "            signals.append('SELL')\n",
    "        else:\n",
    "            signals.append('HOLD')\n",
    "    \n",
    "    # First day has no previous price to compare\n",
    "    signals.insert(0, 'HOLD')\n",
    "    \n",
    "    forecast_df['Signal'] = signals\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(forecast_df['Date'], forecast_df['Predicted_Close'], marker='o', label='Forecasted Price', color='navy')\n",
    "    \n",
    "    # Mark BUY and SELL\n",
    "    for i in range(len(forecast_df)):\n",
    "        if forecast_df.loc[i, 'Signal'] == 'BUY':\n",
    "            plt.scatter(forecast_df.loc[i, 'Date'], forecast_df.loc[i, 'Predicted_Close'], color='green', label='BUY' if i == 0 else \"\", marker='^', s=100)\n",
    "        elif forecast_df.loc[i, 'Signal'] == 'SELL':\n",
    "            plt.scatter(forecast_df.loc[i, 'Date'], forecast_df.loc[i, 'Predicted_Close'], color='red', label='SELL' if i == 0 else \"\", marker='v', s=100)\n",
    "    \n",
    "    plt.title(f\"{ticker} - 7-Day Forecast with Buy/Sell Signals\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Predicted Close Price\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6032d4-c888-45ad-a817-3f09a357ea05",
   "metadata": {},
   "source": [
    "## Generate data for the selected stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a4021-57e7-4ed1-a02e-1fc7fc1cc179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Extract data  \n",
    "# =============================================================================\n",
    "if trading_stratergy == '1':\n",
    "    moving_average(tickers)\n",
    "    support_resistance(tickers)\n",
    "    RSI(tickers)\n",
    "elif trading_stratergy == '2':\n",
    "    intraday(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b5fcc1-7f0b-42a3-9188-3eb9818ec753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, Dense\n",
    "import tensorflow as tf\n",
    "import ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841da17a-03d9-444d-ac29-1c96aacbd71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\n >> Predicted values of {tickers} for next 7 days: \\n')\n",
    "predict_future_values(tickers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
